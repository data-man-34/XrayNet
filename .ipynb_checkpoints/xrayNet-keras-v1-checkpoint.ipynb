{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 40\n",
    "infodir = 'C:/Science Research/xraynet_data/images/images'\n",
    "\n",
    "train_data_dir = f'{infodir}/train'\n",
    "test_data_dir =  f'{infodir}/test'\n",
    "\n",
    "train_h5_path = f'{infodir}/train.h5'\n",
    "test_h5_path = f'{infodir}/test.h5'\n",
    "MODEL_NAME = 'xrayNet-keras-v1.5' #gve the model a name\n",
    "# input image dimensions\n",
    "img_size = 128\n",
    "input_shape = (img_size,img_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5f = h5py.File(train_h5_path, 'r')\n",
    "X = h5f['X']\n",
    "Y = h5f['Y']\n",
    "\n",
    "h5ft = h5py.File(test_h5_path, 'r')\n",
    "test_X = h5ft['X']\n",
    "test_Y = h5ft['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = [l[0] for l in Y]\n",
    "test_Y = [l[0] for l in test_Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "from tflearn.data_utils import shuffle\n",
    "\n",
    "X,Y = shuffle(X,Y)\n",
    "test_X,test_Y = shuffle(test_X,test_Y)\n",
    "\n",
    "X = X.reshape([-1,img_size,img_size,1])\n",
    "test_X = test_X.reshape([-1,img_size,img_size,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir=f'./TBLOGS/{MODEL_NAME}', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 3416 samples\n",
      "Epoch 1/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.2151 - acc: 0.9077 - val_loss: 0.8776 - val_acc: 0.5665\n",
      "Epoch 2/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.2002 - acc: 0.9147 - val_loss: 0.9990 - val_acc: 0.5946\n",
      "Epoch 3/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1891 - acc: 0.9201 - val_loss: 0.8309 - val_acc: 0.5992\n",
      "Epoch 4/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1761 - acc: 0.9260 - val_loss: 0.9596 - val_acc: 0.6036\n",
      "Epoch 5/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1650 - acc: 0.9294 - val_loss: 0.8545 - val_acc: 0.6077\n",
      "Epoch 6/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1601 - acc: 0.9324 - val_loss: 1.1779 - val_acc: 0.5975\n",
      "Epoch 7/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1537 - acc: 0.9344 - val_loss: 0.9733 - val_acc: 0.6077\n",
      "Epoch 8/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1487 - acc: 0.9378 - val_loss: 0.9826 - val_acc: 0.6148\n",
      "Epoch 9/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1399 - acc: 0.9408 - val_loss: 1.2545 - val_acc: 0.5831\n",
      "Epoch 10/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1358 - acc: 0.9431 - val_loss: 1.0412 - val_acc: 0.6241\n",
      "Epoch 11/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1341 - acc: 0.9432 - val_loss: 1.1281 - val_acc: 0.6042\n",
      "Epoch 12/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1287 - acc: 0.9453 - val_loss: 1.1271 - val_acc: 0.5872\n",
      "Epoch 13/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1240 - acc: 0.9479 - val_loss: 1.4187 - val_acc: 0.6016\n",
      "Epoch 14/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1196 - acc: 0.9504 - val_loss: 1.0405 - val_acc: 0.6107\n",
      "Epoch 15/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1163 - acc: 0.9514 - val_loss: 1.3356 - val_acc: 0.6054\n",
      "Epoch 16/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1146 - acc: 0.9518 - val_loss: 1.0184 - val_acc: 0.6191\n",
      "Epoch 17/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1121 - acc: 0.9537 - val_loss: 1.1099 - val_acc: 0.6215\n",
      "Epoch 18/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1075 - acc: 0.9550 - val_loss: 1.2473 - val_acc: 0.5972\n",
      "Epoch 19/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1063 - acc: 0.9559 - val_loss: 1.1815 - val_acc: 0.5893\n",
      "Epoch 20/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1055 - acc: 0.9554 - val_loss: 1.5022 - val_acc: 0.5963\n",
      "Epoch 21/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1026 - acc: 0.9569 - val_loss: 1.3275 - val_acc: 0.6095\n",
      "Epoch 22/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.1015 - acc: 0.9576 - val_loss: 1.6560 - val_acc: 0.5966\n",
      "Epoch 23/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.0974 - acc: 0.9596 - val_loss: 1.4609 - val_acc: 0.6259\n",
      "Epoch 24/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.0960 - acc: 0.9606 - val_loss: 1.2446 - val_acc: 0.6224\n",
      "Epoch 25/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.0940 - acc: 0.9610 - val_loss: 1.0479 - val_acc: 0.5963\n",
      "Epoch 26/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.0919 - acc: 0.9616 - val_loss: 1.3406 - val_acc: 0.5969\n",
      "Epoch 27/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.0906 - acc: 0.9626 - val_loss: 1.3734 - val_acc: 0.6162\n",
      "Epoch 28/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.0895 - acc: 0.9625 - val_loss: 1.6234 - val_acc: 0.6022\n",
      "Epoch 29/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.0867 - acc: 0.9644 - val_loss: 1.6055 - val_acc: 0.5957\n",
      "Epoch 30/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.0844 - acc: 0.9654 - val_loss: 2.0917 - val_acc: 0.5732\n",
      "Epoch 31/40\n",
      "100000/100000 [==============================] - 269s 3ms/step - loss: 0.0831 - acc: 0.9654 - val_loss: 1.2868 - val_acc: 0.6224\n",
      "Epoch 32/40\n",
      "100000/100000 [==============================] - 271s 3ms/step - loss: 0.0832 - acc: 0.9658 - val_loss: 1.5247 - val_acc: 0.6139\n",
      "Epoch 33/40\n",
      "  1664/100000 [..............................] - ETA: 4:26 - loss: 0.0678 - acc: 0.9681"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          verbose=1,\n",
    "          shuffle = True, \n",
    "          validation_data=(test_X,test_Y),    #data to be be used as vailidation\n",
    "          callbacks=[tbCallBack]) #pushes data to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('{}.{}.model'.format(MODEL_NAME,'')) #save the model with the name in the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data[0][0].dtype='int'\n",
    "a = (data[0][0]*255).astype('int')\n",
    "b = (data[0][0]*255).astype('int')\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = [i for i, image in enumerate(data_s) if all((image[0]*255).astype('int') == (data[0][0]*255).astype('int'))]\n",
    "print(ls[70705], labels[70705])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [0,1] == Normal\n",
    "\n",
    "### [1,0] == Abnormal\n",
    "\n",
    "### [Abnormalness, Normalness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##TRAIN##\n",
    "model.fit(data, labels, n_epoch=10, #train the model on the data and corresponding labels\n",
    "           validation_set=.1, #establish set to validate the model on (aka the last 10% of the dataset)\n",
    "           snapshot_step=10000, show_metric=True, run_id=MODEL_NAME) #show the progress of the NN, and give it a name\n",
    "\n",
    "model.save('{}.model'.format(MODEL_NAME)) #save the model with the name in the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##SETUP THE TRAINING##\n",
    "\n",
    "from tflearn.models import dnn #import library for deep neural network\n",
    "model = dnn.DNN(net,tensorboard_verbose=3, best_checkpoint_path=f'{MODEL_NAME}-best-chkpt', best_val_accuracy=0.75) #create the model from the net\n",
    "#establish the directory to store the logs of the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
